{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)\n",
    "\n",
    "#nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: load the data from the npz\n",
    "dataset = np.load('./datasets/v0_eigens.npz') #contains 'train_eigens' and 'issue_eigens'\n",
    "\n",
    "# NOTE: calculate the size of training set and validation set\n",
    "#       all pre-processed features are inside 'train_eigens'\n",
    "train_data_size = dataset['train_eigens'].shape[0] # train_data_size = 57159, (57159, 924)\n",
    "valid_data_size = train_data_size // 5 # valid_data_size= 11431\n",
    "train_data_size = train_data_size - valid_data_size # train_data_size= 45728\n",
    "indices = np.arange(train_data_size + valid_data_size) # indices= [    0     1     2 ... 57156 57157 57158]\n",
    "\n",
    "# NOTE: split dataset\n",
    "train_data = dataset['train_eigens'][indices[:train_data_size]] # [:45728] \n",
    "valid_data = dataset['train_eigens'][indices[train_data_size:]] # [45728:]\n",
    "\n",
    "# NOTE: a 896d feature vector for each user, the 28d vector in the end are\n",
    "#       labels\n",
    "#       896 = 32 (weeks) x 7 (days a week) x 4 (segments a day)\n",
    "# train_data.shape is (45728, 924)\n",
    "train_eigens = train_data[:, :-28] #(45728, 896)\n",
    "train_labels = train_data[:, -28:] #(45728, 28)\n",
    "valid_eigens = valid_data[:, :-28] #(11431, 896)\n",
    "valid_labels = valid_data[:, -28:] #(11431, 28)\n",
    "issue_eigens = dataset['issue_eigens'][:, :-28] #(37092, 896)\n",
    "\n",
    "images = train_eigens\n",
    "labels = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The size of the training input: (45728, 896)\n",
    "#The size of the training label: (45728, 28)\n",
    "#The size of the validation input: (11431, 896)\n",
    "#The size of the validation label: (11431, 28)\n",
    "#The size of the test input: (37092, 896)\n",
    "#The size of the test label: (37092, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write result\n",
    "import csv\n",
    "import os\n",
    "\n",
    "def write_result(name, predictions):\n",
    "    if predictions is None:\n",
    "        raise Exception('need predictions')\n",
    "\n",
    "    predictions = predictions.flatten()\n",
    "\n",
    "    if not os.path.exists('./results/'):\n",
    "        os.makedirs('./results/')\n",
    "\n",
    "    path = os.path.join('./results/', name)\n",
    "\n",
    "    with open(path, 'wt', encoding='utf-8', newline='') as csv_target_file:\n",
    "        target_writer = csv.writer(csv_target_file, lineterminator='\\n')\n",
    "\n",
    "        header = [\n",
    "            'user_id',\n",
    "            'time_slot_0', 'time_slot_1', 'time_slot_2', 'time_slot_3',\n",
    "            'time_slot_4', 'time_slot_5', 'time_slot_6', 'time_slot_7',\n",
    "            'time_slot_8', 'time_slot_9', 'time_slot_10', 'time_slot_11',\n",
    "            'time_slot_12', 'time_slot_13', 'time_slot_14', 'time_slot_15',\n",
    "            'time_slot_16', 'time_slot_17', 'time_slot_18', 'time_slot_19',\n",
    "            'time_slot_20', 'time_slot_21', 'time_slot_22', 'time_slot_23',\n",
    "            'time_slot_24', 'time_slot_25', 'time_slot_26', 'time_slot_27',\n",
    "        ]\n",
    "\n",
    "        target_writer.writerow(header)\n",
    "\n",
    "        for i in range(0, len(predictions), 28):\n",
    "            # NOTE: 57159 is the offset of user ids\n",
    "            userid = [57159 + i // 28]\n",
    "            labels = predictions[i:i+28].tolist()\n",
    "\n",
    "            target_writer.writerow(userid + labels)\n",
    "\n",
    "# define metric AUC\n",
    "import sklearn.metrics\n",
    "\n",
    "def auc(guess, truth):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    guess = guess.flatten()\n",
    "    truth = truth.flatten()\n",
    "    \n",
    "    fprs, tprs, _ = sklearn.metrics.roc_curve(truth, guess)\n",
    "\n",
    "    return sklearn.metrics.auc(fprs, tprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, Activation, Flatten, Bidirectional, LSTM, MaxPool1D, GRU\n",
    "from keras.layers.core import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45728 samples, validate on 11431 samples\n",
      "Epoch 1/11\n",
      "45728/45728 [==============================] - 15s 334us/step - loss: 0.3248 - val_loss: 0.2370\n",
      "Epoch 2/11\n",
      "45728/45728 [==============================] - 5s 109us/step - loss: 0.2300 - val_loss: 0.2245\n",
      "Epoch 3/11\n",
      "45728/45728 [==============================] - 5s 107us/step - loss: 0.2221 - val_loss: 0.2198\n",
      "Epoch 4/11\n",
      "45728/45728 [==============================] - 5s 108us/step - loss: 0.2168 - val_loss: 0.2149\n",
      "Epoch 5/11\n",
      "45728/45728 [==============================] - 5s 108us/step - loss: 0.2119 - val_loss: 0.2114\n",
      "Epoch 6/11\n",
      "45728/45728 [==============================] - 5s 106us/step - loss: 0.2085 - val_loss: 0.2086\n",
      "Epoch 7/11\n",
      "45728/45728 [==============================] - 5s 108us/step - loss: 0.2064 - val_loss: 0.2075\n",
      "Epoch 8/11\n",
      "45728/45728 [==============================] - 5s 108us/step - loss: 0.2050 - val_loss: 0.2073\n",
      "Epoch 9/11\n",
      "45728/45728 [==============================] - 5s 108us/step - loss: 0.2039 - val_loss: 0.2079\n",
      "Epoch 10/11\n",
      "45728/45728 [==============================] - 5s 109us/step - loss: 0.2031 - val_loss: 0.2066\n",
      "Epoch 11/11\n",
      "45728/45728 [==============================] - 5s 109us/step - loss: 0.2024 - val_loss: 0.2064\n",
      "\n",
      "Time elapsed: 65.81930160522461 seconds\n",
      "\n",
      "0.8841765221607314\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(28, activation='relu'))\n",
    "    model.add(Reshape((28,1)))\n",
    "    \n",
    "    model.add(Conv1D(kernel_size = (11), filters = 5, activation='relu'))\n",
    "    model.add(MaxPool1D(pool_size = (1), strides=(1)))    \n",
    "    model.add(Bidirectional(LSTM(5, return_sequences=True)))   \n",
    "    #model.add(GRU(28, return_sequences = True))\n",
    "    #model.add(GRU(32, return_sequences = True))      \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(28, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "images_X = np.expand_dims(images, axis=2)\n",
    "valid_eigens_X = np.expand_dims(valid_eigens, axis=2)\n",
    "\n",
    "model.fit(\n",
    "    images, \n",
    "    labels, \n",
    "    epochs=11, \n",
    "    batch_size=450,\n",
    "    validation_data=(valid_eigens, valid_labels),\n",
    "    shuffle=True)\n",
    "\n",
    "print(\"\\nTime elapsed: {} seconds\\n\".format(time.time() - start))\n",
    "\n",
    "valid_predict= model.predict(valid_eigens)\n",
    "score = auc(\n",
    "    valid_predict, \n",
    "    valid_labels\n",
    ")\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8838898227839855 #kaggle 0.87968\n",
    "    model = Sequential()\n",
    "    model.add(Dense(28, activation='relu'))\n",
    "    model.add(Reshape((28,1)))\n",
    "    \n",
    "    model.add(Conv1D(kernel_size = (9), filters = 5, input_shape=(896, 1), activation='relu'))\n",
    "    model.add(MaxPool1D(pool_size = (1), strides=(1)))\n",
    "    model.add(Bidirectional(LSTM(5, return_sequences=True)))     \n",
    "    #model.add(GRU(28, return_sequences = True))\n",
    "    #model.add(GRU(32, return_sequences = True))      \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(28, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "\n",
    "0.8843608681364775 # kaggle 0.88043\n",
    "    model.add(Conv1D(kernel_size = (11), filters = 5, input_shape=(896, 1), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time elasped: 16.965404987335205 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "issue_eigens_X = np.expand_dims(issue_eigens, axis=2)\n",
    "issue_guesss = model.predict(issue_eigens)\n",
    "write_result('tf101_model_d.csv', issue_guesss)\n",
    "\n",
    "print(\"\\nTime elasped: {} seconds\\n\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 28)                25116     \n",
      "_________________________________________________________________\n",
      "reshape_27 (Reshape)         (None, 28, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 18, 5)             60        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 18, 5)             0         \n",
      "_________________________________________________________________\n",
      "bidirectional_25 (Bidirectio (None, 18, 10)            440       \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 28)                5068      \n",
      "=================================================================\n",
      "Total params: 30,684\n",
      "Trainable params: 30,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45728 samples, validate on 11431 samples\n",
      "Epoch 1/11\n",
      "45728/45728 [==============================] - 10s 220us/step - loss: 0.3729 - val_loss: 0.2363\n",
      "Epoch 2/11\n",
      "45728/45728 [==============================] - 1s 13us/step - loss: 0.2257 - val_loss: 0.2207\n",
      "Epoch 3/11\n",
      "45728/45728 [==============================] - 1s 13us/step - loss: 0.2185 - val_loss: 0.2191\n",
      "Epoch 4/11\n",
      "45728/45728 [==============================] - 1s 13us/step - loss: 0.2152 - val_loss: 0.2152\n",
      "Epoch 5/11\n",
      "45728/45728 [==============================] - 1s 12us/step - loss: 0.2125 - val_loss: 0.2138\n",
      "Epoch 6/11\n",
      "45728/45728 [==============================] - 1s 12us/step - loss: 0.2100 - val_loss: 0.2111\n",
      "Epoch 7/11\n",
      "45728/45728 [==============================] - 1s 12us/step - loss: 0.2074 - val_loss: 0.2097\n",
      "Epoch 8/11\n",
      "45728/45728 [==============================] - 1s 12us/step - loss: 0.2056 - val_loss: 0.2138\n",
      "Epoch 9/11\n",
      "45728/45728 [==============================] - 1s 12us/step - loss: 0.2041 - val_loss: 0.2086\n",
      "Epoch 10/11\n",
      "45728/45728 [==============================] - 1s 13us/step - loss: 0.2030 - val_loss: 0.2076\n",
      "Epoch 11/11\n",
      "45728/45728 [==============================] - 1s 13us/step - loss: 0.2022 - val_loss: 0.2071\n",
      "\n",
      "Time elapsed: 16.043700218200684 seconds\n",
      "\n",
      "0.8830348265290564\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(28, activation='elu'))\n",
    "    model.add(Dense(28, activation='elu'))\n",
    "    model.add(Dense(28, activation='relu'))\n",
    "    model.add(Dense(28, activation='relu'))\n",
    "    model.add(Dense(28, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "images_X = np.expand_dims(images, axis=2)\n",
    "valid_eigens_X = np.expand_dims(valid_eigens, axis=2)\n",
    "\n",
    "model.fit(\n",
    "    images, \n",
    "    labels, \n",
    "    epochs=11, \n",
    "    batch_size=450,\n",
    "    validation_data=(valid_eigens, valid_labels),\n",
    "    shuffle=True)\n",
    "\n",
    "print(\"\\nTime elapsed: {} seconds\\n\".format(time.time() - start))\n",
    "\n",
    "valid_predict= model.predict(valid_eigens)\n",
    "score = auc(\n",
    "    valid_predict, \n",
    "    valid_labels\n",
    ")\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 28)                25116     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 28)                812       \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 28)                812       \n",
      "=================================================================\n",
      "Total params: 28,364\n",
      "Trainable params: 28,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
